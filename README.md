# AutoTweeter AI
The purpose of AutoTweeter AI is to automate a user's Twitter feed using content researched, created and moderated by an AI that operates fully autonomously.

AutoTweeter is composed of two components:
- AutoTweeter AI: This repo, which is created as Lambda function that uses as an input a CSV dump of all Tweets written on a user's Twitter feed to generate new Tweets based on current events pulled from the Reddit API.
- Google Sheet: A Google Sheet serves as the database where generated Tweets are deposited. Within the Google Sheet there is a Google Apps Script which will run on a periodic basis and randomly select a Tweet within it and publish it to a user's Twitter feed.

## Pre-requisites
- Register a Reddit app [here](https://ssl.reddit.com/prefs/apps/) 
    - Set it up as a "Personal Use Script"
    - Note down the ClientID and ClientSecret (which will be emailed to you)
- Register for an [OpenAI API Key](https://platform.openai.com/account/api-keys) and API access to GPT-4 model.
- Setup the Google Sheet that will be used for publishing Tweets generated by this code, follow the instructions found [here](https://www.bluelabellabs.com/blog/how-to-create-a-twitter-bot-in-google-sheets-using-a-google-apps-script/).
- Setup a Google Cloud Project here.
    - Enable Google Sheets API within the project.
    - Create a OAuth2 ClientID and ClientSecret, download the credentials .json file that Google creates. Copy this json file into the project directory locally.
    - Create a Service Account within the project.
    - Within the Google Sheet setup previously, add the Email address of the Service Account created with "Write" permissions on the Sheet.
- An AWS account where the Lambda function for the AutoTweeter can be deployed and run.
- Setup a PromptLayer API key [here](https://promptlayer.com/home). PromptLayer is a free tool that gives you a very easy way to visually debug prompts sent to an LLM.
- Obtain a CSV dump of the Tweet history for the Twitter user account you are looking to automate, follow the instructions [here](https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive). 

## Installing Dependencies

This code project requires the following to be installed on your development machine:
- NodeJS (16.15.1+)
- Serverless Framework
- Python 3.10

Install all Python dependencies using the enclosed requirements.txt file:
```
pip install -r requirements.txt
```

Install all Node dependencies needed by the Serverless framework by running:
```
npm install
```

Ensure you have set in your environment variables your OpenAI API key. If you are using bash, then add this to your **~/.bash_profile**:
```
export OPENAI_API_KEY="<OPENAI API KEY>"
```

## Setup Steps

1.) Create a new file named **config.py** , with the following values:
```python
REDDIT_CLIENT_ID="<ClientID of Reddit App>"
REDDIT_CLIENT_SECRET="<Client Secret of Reddit App>"
REDDIT_USER_AGENT="AutoTweeter2 by <Your Reddit Username>"
PROMPT_LAYER_API_KEY="<PromptLayer API Key>"
GOOGLESHEET_ID="<Google Sheet ID that you setup>"
```
2.) Copy the credentials.json file for the Google OAuth Client into the root of the project. Update the name of that file in the **constants.py** file:
```python
GOOGLESHEET_CREDENTIALS_FILE="autotweeter-credentials.json"
```

3.) Copy the CSV file containing the Twitter user's previous Tweet data into the root of the project. Update the name of that file in the **constants.py** file:
```python
SAMPLE_TWEETS_FILENAME="tweets-nolinks-nort-noreply.csv"
```

## Debug and Run Locally in VS Code
The project contains a **launch.json** which will debug the code using a call to the main method in local_handler.py.

## Deploying to Lambda
Deploying the code to run on an automated schedule defined in the **serverless.yml** file can be done using the following command:
```
serverless deploy
```